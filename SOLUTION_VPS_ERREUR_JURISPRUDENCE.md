# Solution pour l'erreur JSON sur VPS - Extraction Jurisprudence

## Probl√®me
Lors de l'analyse de 200 PDFs de jurisprudence, vous obtenez l'erreur:
```
Erreur de connexion: Unexpected token '<', "<html> <h"... is not valid JSON
```

Cette erreur signifie que l'API OpenRouter renvoie du HTML (une page d'erreur) au lieu de JSON, car vous atteignez les **limites de taux** (rate limits).

## Solution 1: R√©duire le nombre de requ√™tes parall√®les (RAPIDE ‚úÖ)

Sur votre VPS, modifiez le fichier `app/services/pdf_jurisprudence_extractor.py`:

**Ligne 337** - Changez:
```python
with ThreadPoolExecutor(max_workers=3) as executor:
```

En:
```python
with ThreadPoolExecutor(max_workers=1) as executor:
```

Cela r√©duira les requ√™tes parall√®les de 3 √† 1, √©vitant ainsi de surcharger l'API.

## Solution 2: Ajouter des d√©lais entre les requ√™tes (RECOMMAND√â ‚úÖ‚úÖ)

Dans le fichier `app/services/pdf_jurisprudence_extractor.py`:

**En haut du fichier** (apr√®s les autres imports, vers ligne 20), ajoutez:
```python
import time
```

**Ligne 160** (juste apr√®s `jurisprudence_data = extract_jurisprudence_data_with_ai(...)`), ajoutez:
```python
jurisprudence_data = extract_jurisprudence_data_with_ai(text, filename, api_key, pdf_path, num_pages)

# NOUVEAU: Ajouter un d√©lai pour √©viter de surcharger l'API
time.sleep(2)  # Pause de 2 secondes entre chaque requ√™te

return {
```

## Solution 3: Am√©liorer la gestion d'erreur (TR√àS RECOMMAND√â ‚úÖ‚úÖ‚úÖ)

Dans `app/services/pdf_jurisprudence_extractor.py`, **remplacez les lignes 91-100** par:

```python
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=90
        )
        response.raise_for_status()
        
        # V√©rifier si la r√©ponse est du JSON valide
        try:
            result = response.json()
        except json.JSONDecodeError:
            # La r√©ponse n'est pas du JSON (probablement du HTML)
            error_preview = response.text[:500] if len(response.text) > 500 else response.text
            logger.error(f"R√©ponse non-JSON de l'API: {error_preview}")
            raise Exception(f"L'API a renvoy√© une r√©ponse invalide (HTML au lieu de JSON). Cela indique probablement une limite de taux atteinte. Essayez de r√©duire le nombre de PDFs analys√©s simultan√©ment ou ajoutez des d√©lais entre les requ√™tes.")
        
        # V√©rifier que la structure de la r√©ponse est correcte
        if 'choices' not in result or not result['choices']:
            error_msg = result.get('error', {}).get('message', 'Structure de r√©ponse invalide')
            raise Exception(f"Erreur de l'API OpenRouter: {error_msg}")
        
        ai_response = result['choices'][0]['message']['content']
```

## Solution 4: Traiter par lots plus petits (MEILLEURE PRATIQUE ‚úÖ‚úÖ‚úÖ)

Au lieu d'analyser 200 PDFs d'un coup, faites plusieurs sessions:
- Session 1: 50 PDFs ‚Üí Analyser ‚Üí T√©l√©charger le r√©sultat
- Session 2: 50 PDFs ‚Üí Analyser ‚Üí T√©l√©charger le r√©sultat
- Session 3: 50 PDFs ‚Üí Analyser ‚Üí T√©l√©charger le r√©sultat
- Session 4: 50 PDFs ‚Üí Analyser ‚Üí T√©l√©charger le r√©sultat

Ensuite, fusionnez les 4 fichiers Excel/CSV.

## Solution Combin√©e ULTIME üéØ

Pour de meilleurs r√©sultats, combinez les solutions:

1. ‚úÖ R√©duisez `max_workers` √† 1 (ligne 337)
2. ‚úÖ Ajoutez `time.sleep(2)` apr√®s chaque extraction (ligne 160)
3. ‚úÖ Am√©liorez la gestion d'erreur (lignes 91-100)
4. ‚úÖ Traitez par lots de 30-50 PDFs maximum

## Comment appliquer les changements sur votre VPS

1. **Connectez-vous √† votre VPS via SSH**

2. **Naviguez vers le dossier de votre application**
```bash
cd /chemin/vers/votre/application
```

3. **√âditez le fichier**
```bash
nano app/services/pdf_jurisprudence_extractor.py
```

4. **Appliquez les modifications** (Solutions 1, 2 et 3 ci-dessus)

5. **Sauvegardez** (Ctrl+O puis Entr√©e, puis Ctrl+X pour quitter nano)

6. **Red√©marrez votre application**
```bash
# Si vous utilisez systemd
sudo systemctl restart votre-app

# Ou si vous utilisez PM2
pm2 restart votre-app

# Ou si vous utilisez gunicorn directement
pkill gunicorn
gunicorn --bind 0.0.0.0:votre-port main:app
```

## V√©rification des cr√©dits OpenRouter

Il est aussi possible que vous ayez √©puis√© votre quota/cr√©dit API:

1. Allez sur https://openrouter.ai/
2. Connectez-vous √† votre compte
3. V√©rifiez votre solde et vos limites
4. Rechargez votre compte si n√©cessaire

## R√©sum√©

L'erreur vient du fait que vous envoyez **trop de requ√™tes trop rapidement** √† l'API OpenRouter. La solution est de:
- R√©duire les workers parall√®les (1 au lieu de 3)
- Ajouter des pauses entre les requ√™tes (2 secondes)
- Traiter par lots plus petits (30-50 PDFs au lieu de 200)

Avec ces changements, vous devriez pouvoir analyser vos PDFs sans erreur.
